
# Standalone

## Pros

- Easy to install.
- Good for running and debugging purposes.
- Beginner friendly.
- Setup does not take much time, some can focus on logic and application development.
## Cons:
- Cannot handle large set of data.
- One cannot experience cluster-based architecture.




## Deployment

### Pre-requisites
- Python3
- Java 1.8.0

To deploy this project follow below steps

```bash
Download Spark executable from below link and install it
https://spark.apache.org/downloads.htm
```

```bash
Set User Environment Variable:
SPARK_HOME: C:\Spark\spark-3.1.3-bin-hadoop2.7
```

```bash
Create an entry under path variable as: %SPARK_HOME%\bin.
```

```bash
Set User Environment Variable:
JAVA_HOME: C:\Softwares\Java\jdk1.8.0_333
```
```bash
Create an entry under path variable as: %JAVA_HOME%\bin.
```
```bash
Install pyspark using command: pip install pyspark.
```


